<p align="center">
    <a href="https://scrapingapi.io" target="_blank">
        <img src="https://raw.githubusercontent.com/scrapingapi/scraper/main/logo_text.png" alt="ScrapingAPI Logo" />
    </a>
</p>

<h1 align="center">One API to scrape all the web</h1>

<p align="center">
    Easily scrape data from any website, without taking care of captchas and bot detection mecanisms.
</p>


<div align="center">
 
![version](https://img.shields.io/github/tag/scrapingapi/scraper)
[![npm](https://img.shields.io/npm/dm/scrapingapi)](https://www.npmjs.com/package/scrapingapi)
[![discord](https://img.shields.io/discord/956821594372714546?label=Discord)](https://discord.gg/m7KWXcBaBu)

</div>

<p align="center">
    <a href="http://www.scrapingapi.io"><b>Website</b></a> â€¢
    <a href="https://discord.gg/m7KWXcBaBu"><b>Discord</b></a>
</p>  

<p align="center"><img src="https://raw.githubusercontent.com/scrapingapi/scraper/main/sample_code.png" alt="How does ScraperAPI works" width="1000px" /></p>

## Features

* Fully automated **proxy rotation** with HQ **residential IPs**. No captcha, and you will never be detected as a bot or proxy user
* Integrated [**data extraction**](#extractors) with CSS / jQuery selectors, **filters** and **iterators**
* **Bulk requests**: Up to 3 per call
* Allowed to send json / form-encoded body and cookies
* Returns **response body, headers, final URL & status code**
* Supports redirects 
* Coming Soon: Presets for popular websites

------------

## Get started in 5 minutes chrono

1. **Install** the package from NPM
    ```console
    npm install --save scrapingapi
    ```

2. Create your **API Key** on [scrapingapi.io](https://scrapingapi.io/?utm_source=github&utm_medium=readme)

3. **Enjoy** scraping without headaches !

ðŸ’¡ **TIP**: You can test your requests with [Insomnia](https://github.com/Kong/insomnia) (Open Source + Cross Platform)

## Simple Usage Example

Here is an example of scraping **current Bitcoin price + search results** from Google Search.

```javascript
import Scraper, { $ } from '../src';
const page = new Scraper('API_KEY');

page.get("https://www.google.com/search?q=bitcoin", { device: "desktop" }, {
    // Extract the current bitcoin price                  
    price: $("#search .obcontainer .card-section > div:eq(1)").filter("price"),
    // For each Google search result
    results: $("h2:contains('Web results') + div").each({
        // We retrieve the URL
        url: $("a[href]").attr("href").filter("url"),
        // ... And the title text
        title: $("h3")
    })
}).then( data => {

    console.log("Here are the results:", data);

});
```

The `Scraper.get` method sends a **GET request** to the provided URL, and returns a `Promise` with a `TScrapeResult` object.

ðŸš€ Jump to: [Request methods](#request-methods) / [Request options](#request-options) / [Response object](#response)

![Google Search Example](https://raw.githubusercontent.com/scrapingapi/scraper/main/google-dom.jpg "Google Search Example")

### You will get the following result

```json
{
    "url": "https://www.google.com/search?q=bitcoin",
    "status": 200,
    "data": {
        "price": {
            "amount": 49805.02,
            "currency": "EUR"
        },
        "results": [{
            "url": "https://bitcoin.org/",
            "title": "Bitcoin - Open source P2P money"
        }, {
            "url": "https://coinmarketcap.com/currencies/bitcoin/",
            "title": "Bitcoin price today, BTC to USD live, marketcap and chart"
        }, {
            "url": "https://www.bitcoin.com/",
            "title": "Bitcoin.com | Buy BTC, ETH & BCH | Wallet, news, markets ..."
        }, {
            "url": "https://en.wikipedia.org/wiki/Bitcoin",
            "title": "Bitcoin - Wikipedia"
        }]
    }
}
```

ðŸš€ Jump to: [Response object](#response)

### Are you using Typescript / ESM ?

**ESM** imports are also supported.
If you're using **Typescript**, it's advised to use `import` instead of `require` in order to benefit from type checkings.

```javascript
import Scraper from 'scrapingapi';
const scraper = new Scraper(API_KEY);
```

### Extracted data typing

In addition of basic type checkings, you can **define the type** of the scraped data.

```typescript
...

type BitcoinGoogleResults = {
    // Metadata generated by the price filter
    price: {
        amount: number, 
        currency: string 
    },
    // An array containing an informations object for each Google search result
    results: {
        url: string,
        title: string
    }[]
}

scraper.get<BitcoinGoogleResults>("https://www.google.com/search?q=bitcoin").then( ... );
```

------------------

# Documentation

* [Request](#request)
    - [Methods](#request-methods)
    - [Options](#request-options)
* [Extractors](#extractors)
    - [Value Extractor](#value-extractor)
    - [Item Extractor](#item-extractor)
* [Response](#response)
* [Example](#another-example)

## Request

### Request Methods

This library provides one method per supported HTTP method:

```typescript
public get( url: string, options?: TOptions, extract?: TExtractor ): Promise<TScrapeResult>;
```

[Go to code](https://github.com/scrapingapi/scraper/blob/main/src/index.ts#L56)

```typescript
public post( url: string, body?: any, bodyType?: string, options?: TOptions, extract?: TExtractor ): Promise<TScrapeResult>;
```

[Go to code](https://github.com/scrapingapi/scraper/blob/main/src/index.ts#L56)

With the `scrape` method, You can also send up to **3 requests per call** if each of them points to different domain names.

```typescript
public scrape( requests: TRequestWithExtractors[] ): Promise<TScrapeResult[]>;
```

[Go to code](https://github.com/scrapingapi/scraper/blob/main/src/index.ts#L31)

ðŸš€ Jump to: [Request options](#request-options) / [Extractors](#extractors) / [Response object](#response)

### Request Options

Each request options is represented by the `TRequestWithExtractors` type (the following definition is a simplified version):

```typescript
type TRequestWithExtractors = {
    
    // The URL address you want to sent the request to
    url: string,
    // The HTTP method. Default value: "GET"
    method?: HttpMethod,
    // The cookie string you want to pass to the request.
    // Example: "sessionId=34; userId=87;"
    cookies?: string,

    // The data to send with the request. Must be combined with bodyType.
    // Example: { "name": "bob", "age": 25 }
    body: { [key: string]: any },
    bodyType: typeof bodyTypes[number],

    // Extractor object that define what data you want to extract from the webpage
    extract?: TExtractor,
    // true if you want to retrieve the response body string
    withBody?: boolean,
    // true if you want to retrieve the response headers
    withHeaders?: boolean,
}
```

ðŸ’¡ See: [Allowed HTTP Methods](https://github.com/scrapingapi/scraper/blob/main/src/types.ts#L5) / [Allowed Body Types](https://github.com/scrapingapi/scraper/blob/main/src/types.ts#L6) 

## Extractors

As you've seen before, besides of providing an undetectable scraping proxy, the scrapingapi library also allows you to **extract and filter data** from webpages with the optional `extract` option.

There are two types of extractors that you can combine with each other.

```typescript
type TExtractor = TValueExtractor | TItemsExtractor;
```

### Value extractor

As indicated by his name, the value extractor gives you the tools so you can easily extract data from a webpage.

```typescript
type TValueExtractor = [
    selector: "this" | string, 
    attribute: "text" | "html" | string,
    required: boolean,
    ...filters: string[]
]
```

Its a an array composed by at least three values:

1. **Selector**: A [CSS](https://www.w3schools.com/cssref/css_selectors.asp) / [jQuery-like selector](https://www.w3schools.com/jquery/jquery_ref_selectors.asp) to match the DOM element you are interested in. By example:
    - `h3`: Simply matches all `h3` elements
        - Matches: 
            ```html
            <h3>This is a title</h3>
            ```
        - Do not matches because it's not a `h3` element:
            ```html
            <p>Hello</p>
            ```
    - `a.myLink[href]`: Matches `a` elements having the class `myLink`, and where the `href` attribute is defined
        - Matches: 
            ```html
            <a class="myLink anotherclass" href="https://scrapingapi.io">Link Text</a>
            ```
        - Do not matches, because it doesn't contains the `myLink` class
            ```html
            <a class="thisClassIsAlone" href="https://scrapingapi.io">Link Text</a>
            ```
    - `h2:contains('Scraping API') + div`: Matches `div` elements that are next to `h2` elements where the content is equal to `Scraping API`
        - Matches: 
            ```html
            <h2>Scraping API</h2>
            <div>is cool</div>
            ```
        - Do not matches, because the `div` element is not next to the `h2` element
            ```html
            <h2>Scraping API</h2>
            <p>is maybe not</p>
            <div>well configured</div>
            ```

2. **Attribute**: The DOM element attribute that contains the value you want to extract. It includes:
    - [Native HTML attributes](https://www.w3schools.com/tags/ref_attributes.asp): `href`, `class`, `src`, etc ...
    - `"text"`: Get the element content text. Leading, trailing and repeated whitespaces will be removed, ans HTML entities are decoded.
    - `"html"`: Get the element content html

3. **Required**: A boolean that specify if this value is essential or not. 
    If no value has been found and if required is true, then the whole item will not be included in the response.

4. **Filters**: All the following values are filters that will be applied to the extracted value. Here are built-in filters:
    - URL
    - Price

#### By Example

```typescript
[".priceText", "text", true, "price"],
```

1. Select all elements having the `.priceText` class
2. Get the **content text** of each of theses elements. Example:
    ```json
    "Current price: 9.99 $ (taxes included)"
    ```
3. This data is **required**, it should be present in the response
4. Process the data by passing it to the **price filter**. You will get:
    ```json
    { "amount": 9.99, "currency": "USD" }
    ```

### Item extractor

```typescript
type TItemsExtractor = (
    { $foreach?: string }
    &
    { [name: string]: TExtractor }
)
```

The item extractor has 3 use cases. To illustrate them, I will take back the [Bitcoin Google Search example](#simple-usage-example).

* **Give a name** to every value you've extracted
    ```typescript
    {
        price: ["#search .obcontainer .card-section > div:eq(1)", "text", true, "price"],
    }
    ```
* **Define a structure** for your data (you can nest multiple item extractors)
    ```typescript
    {
        informations: {
            price: ["#search .obcontainer .card-section > div:eq(1)", "text", true, "price"],
        }               
    }
    ```
* **Iterate** a DOM elements list to return an array correspond to each element (see the `$foreach` instruction)
    ```typescript
    {              
        price: ["#search .obcontainer .card-section > div:eq(1)", "text", true, "price"],
        results: {
            $foreach: "h2:contains('Web results') + div", // This is our iterator
            url: ["a[href]", "href", true, "url"],
            title: ["h3", "text", true]
        }
    }
    ```

#### The $foreach instruction

The `$foreach` instruction allows you to iterate all items that matches a selector.

**Important**: Please note that all the selectors that follows - directly or indirectly - a `$foreach` instruction will be relative to the matched items. 
Consider the following extractor:

```typescript
{
    $foreach: "article.product",
    name: ["> h3", "text", true],
}
```

It goal is to extract the title of every `article` element having the product class.

Since we've iterated across items via a `$foreach`, the `> h3` selector will be executed inside every `article.product` element.

In other words, the `name` data will match every `h3` element that is a direct child of every `article.product` element.

## Response

For each request you send, a `TScrapeResult` object will be returned, containing the informations you've requested in the options.

```typescript
type TScrapeResult<TData extends any = any> = {

    // The final response URL. Useful if the requested webpage send redirections.
    url: string,

    // The response HTTP status code. 200 if it is ok.
    status: number,
    
    // When you set the `withHeaders` option to true, an object containing the webpage response headers will be returned.
    headers?: { [key: string]: string },

    // When you set the `withBody` option to true, you will get the HTML of the requested webpage.
    body?: string,

    // When you specify extractors with the `extract` option, data will contain the extracted data.
    data?: TData
}
```

ðŸ’¡ Additionnal Resources: [List of HTTP status codes](https://wikipedia.org/wiki/List_of_HTTP_status_codes).

### Optimize the response time

Disable theses options as soon as you can:

* extract
* withBody
* withHeaders

While theses three features can be useful, it uses additionnal CPU resources, slows down communication between our proxies and our server and increase response size.

## Another example

Consider that `http://example.com/products` responds with a webpage containing the following HTML:

```html
<h2>Space Cat Holograms to motive you programming</h2>
<p>Free shipping to all the Milky Way.</p>
<section id="products">

    <article class="product">
        <img src="https://wallpapercave.com/wp/wp4014371.jpg" />
        <h3>Sandwich cat lost on a burger rocket</h3>
        <strong class="red price">123.45 $</strong>
        <ul class="tags">
            <li>sandwich</li>
            <li>burger</li>
            <li>rocket</li>
        </ul>
    </article>

    <article class="product">
        <img src="https://wallpapercave.com/wp/wp4575175.jpg" />
        <h3>Aliens can't sleep because of this cute DJ</h3>
        <ul class="tags">
            <li>aliens</li>
            <li>sleep</li>
            <li>cute</li>
            <li>dj</li>
            <li>music</li>
        </ul>
    </article>

    <article class="product">
        <img src="https://wallpapercave.com/wp/wp4575192.jpg" />
        <h3>Travelling at the speed of light with a radioactive spaceship</h3>
        <p class="details">
            Warning: Contains Plutonium.
        </p>
        <strong class="red price">456.78 $</strong>
        <ul class="tags">
            <li>pizza</li>
            <li>slice</li>
            <li>spaceship</li>
        </ul>
    </article>

    <article class="product">
        <img src="https://wallpapercave.com/wp/wp4575163.jpg" />
        <h3>Gentleman dropped his litter into a black hole</h3>
        <p class="details">
            Since he found this calm planet.
        </p>
        <strong class="red price">undefined</strong>
        <ul class="tags">
            <li>luxury</li>
            <li>litter</li>
        </ul>
    </article>
</section>
```

Let's extract the product list: 

```typescript
type Product = {
    name: string,
    image: string,
    price: { amount: number, currency: string },
    tags: { text: string }[],
    description?: string
}

scraper.get<Product[]>("http://example.com/products", {}, {
    
    $foreach: "#products > article.product",

    name: ["> h3", "text", true],
    image: ["> img", "src", true, "url"],
    price: ["> .price", "text", true, "price"],
    tags: {
        $foreach: "> ul.tags > li",
        text: ["this", "text", true]
    },
    description: ["> .details", "text", false]

});
```

Here is the response:

```json
{
    "url": "http://example.com/products",
    "status": 200,
    "data": [{
        "name": "Sandwich cat lost on a burger rocket",
        "image": "https://wallpapercave.com/wp/wp4014371.jpg",
        "price": { "amount": 123.45, "currency": "USD" },
        "tags": [
            { "text": "sandwich" },
            { "text": "burger" },
            { "text": "rocket" }
        ]
    },{
        "name": "Gentlemen can't find his litter anymore",
        "image": "https://wallpapercave.com/wp/wp4575192.jpg",
        "price": { "amount": 456.78, "currency": "USD" },
        "tags": [
            { "text": "pizza" },
            { "text": "slice" },
            { "text": "spaceship" }
        ]
    }]
}
```

Did you notice ? In the request, the `price` data has been marked as required. but for two HTML elements we've iterated with the `$foreach` instruction, **the extractor wasn't able to extract the price**.

* `Aliens can't sleep because of this cute DJ` doesn't contains any element that matches with `> .price`
* `Gentleman dropped his litter into a black hole` contains a `.price` element, but the content text doesn't represents a price

-----------

# About

## Need any additional information or help ? 

* Search if a related issue [has not been created before](https://github.com/scrapingapi/scraper/issues)
* If not, feel free to [create a new issue](https://github.com/scrapingapi/scraper/issues/new)
* For more personal questions, or for profesionnal inquiries: 
    <details>
    <summary>Send me an email</summary>

    `contact@gaetan-legac.fr`
    </details>

## Credits

For any complaint about abused kittens that has been sent to the deep space, see it with [WallpaperCave](https://wallpapercave.com/space-cat-wallpapers).